{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoConfig\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, 'scripts')\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load model\n",
    "model_checkpoint_path = {\n",
    "    'claims': 'model/for_claims/checkpoint/train-300-t1',\n",
    "    'premises': 'model/for_premises/checkpoint/train-300-p1'\n",
    "}\n",
    "scenario = ['auto-driving', 'bitcoin-invest']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dingdong/anaconda3/envs/transformers/lib/python3.9/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "2022-08-27 14:27:21.873102: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "for task, model_path in model_checkpoint_path.items():\n",
    "    config = AutoConfig.from_pretrained(model_path)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "    for sc in scenario:\n",
    "        data = pd.read_csv(os.path.join('data', task, f\"evaluation-{sc}.csv\"))\n",
    "        inputs = tokenizer(data.text.to_list(), max_length=300,\n",
    "                           return_tensors='pt', padding=True, truncation=True)\n",
    "        summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "        output = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n",
    "        df = pd.DataFrame({\n",
    "            'text': data.text.tolist(),\n",
    "            'ground-truth': data[task[:-1]].tolist(),\n",
    "            'prediction': output\n",
    "        })\n",
    "        df.to_csv(os.path.join('data/prediction_results', f'prediction-results-{sc}-{task}.csv'), index=False)\n",
    "    del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from load_data import find_xml_files, load_objects, load_data\n",
    "# data = load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill data json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from evaluate_data import locate_post, create_objects, insert_objects\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    'data/prediction_results/prediction-results-auto-driving-claims.csv')\n",
    "with open('datasets/auto-driving/Would-you-get-into-a-self-driving-car_0820_1.json') as f:\n",
    "    data_file = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8e1bf47af242c2840e417002a6f971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match found in 32th post\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_post = 0\n",
    "for i, txt in tqdm(enumerate(df.text)):\n",
    "    try:\n",
    "        target_post = locate_post(data_file['answers'], txt, start_index=target_post)\n",
    "        if target_post == -1:\n",
    "            raise ValueError(f\"No match found in {i}th post\")\n",
    "    except ValueError as err:\n",
    "        print(err)\n",
    "    prediction = df.loc[i,'prediction']\n",
    "    fill_objects = create_objects(prediction)\n",
    "    data_file['answers'] = insert_objects(\n",
    "        data_file['answers'], fill_objects, target_post, 'claim')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'model/for_claims/checkpoint/train-300-t1'\n",
    "config = AutoConfig.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
    "input_text = \"Try thinking of investing in bitcoin as you would buying a lottery ticket. It only costs a dollar, but you could win big. However, as historically shown with commodities, the odds are good that you're going to lose money compared with a low-cost, diversified investment.Bitcoin is open to everyone and provides an exciting opportunity to delve into an entirely new asset class. Investing in bitcoin may seem scary, but know that it takes time and effort to understand how Bitcoin works. Also keep in mind that the Bitcoin are varied. Keep that in mind, and do your own research based on where you live.\"\n",
    "\n",
    "inputs = tokenizer(input_text,\n",
    "                   return_tensors='pt', padding=True, truncation=True)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"])\n",
    "output = tokenizer.batch_decode(summary_ids, skip_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Try thinking of investing in bitcoin as you would buying a lottery ticket. It only costs a dollar\\nkeep that in mind, and do your own research based on where you live.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus(input_text, max_length=300, padding=True, add_special_tokens=True, return_tensors=\"pt\")\n",
    "summary_ids = model.generate(\n",
    "    inputs['input_ids'], max_length=150, do_sample=True, top_p=0.95, top_k=60)\n",
    "inferences = []\n",
    "for i,x in enumerate(summary_ids):\n",
    "    inferences.append(tokenizer.decode(summary_ids[i], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Try thinking of investing in bitcoin as you would buying a lottery ticket. It only costs a dollar\\nbecause of it takes time and effort to understand how Bitcoin works.\\nkeep that in mind, and do your own research based on where you live.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inferences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('transformers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8220953b88f764fcdbd0075b4138a91f664c10d8705b38466fc99d87a409cf1b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
